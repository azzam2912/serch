a related and somewhat synonymous term is single instance data storage this technique is used to improve storage utilization and can also be applied to network data transfers to reduce the number of bytes that must be sent in the deduplication process unique chunks of data or byte patterns are identified and stored during a process of analysis as the analysis continues other chunks are compared to the stored copy and whenever a match occurs the redundant chunk is replaced with a small reference that points to the stored chunk given that the same byte pattern may occur dozens hundreds or even thousands of times the match frequency is dependent on the chunk size the amount of data that must be stored or transferred can be greatly reduced deduplication is different from data compression algorithms such as lz77 and lz78 whereas compression algorithms identify redundant data inside individual files and encodes this redundant data more efficiently the intent of deduplication is to inspect large volumes of data and identify large sections such as entire files or large sections of files that are identical and replace them with a shared copy for example a typical email system might contain 100 instances