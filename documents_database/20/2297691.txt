the test was developed by halbert white who observed that in a correctly specified model and under standard regularity assumptions the fisher information matrix can be expressed in either of two ways as the outer product of the gradient or as a function of the hessian matrix of the log likelihood function consider a linear model formula 1 where the errors formula 2 are assumed to be distributed formula 3 if the parameters formula 4 and formula 5 are stacked in the vector formula 6 the resulting log likelihood function is the information matrix can then be expressed as that is the expected value of the outer product of the gradient or score second it can be written as the negative of the hessian matrix of the log likelihood function if the model is correctly specified both expressions should be equal combining the equivalent forms yields where formula 11 is an formula 12 random matrix where formula 13 is the number of parameters white showed that the elements of formula 14 where formula 15 is the mle are asymptotically normally distributed with zero means when the model is correctly specified in small samples however the test generally performs poorly