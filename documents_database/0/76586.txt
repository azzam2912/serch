specifically no more than 1 k of the distribution s values can be more than k standard deviations away from the mean or equivalently at least 1 1 k of the distribution s values are within k standard deviations of the mean the rule is often called chebyshev s theorem about the range of standard deviations around the mean in statistics the inequality has great utility because it can be applied to any probability distribution in which the mean and variance are defined for example it can be used to prove the weak law of large numbers in practical usage in contrast to the 68 95 99 7 rule which applies to normal distributions chebyshev s inequality is weaker stating that a minimum of just 75 of values must lie within two standard deviations of the mean and 89 within three standard deviations the term chebyshev s inequality may also refer to markov s inequality especially in the context of analysis they are closely related and some authors refer to markov s inequality as chebyshev s first inequality and the similar one referred to on this page as chebyshev s second inequality the theorem is named after russian mathematician pafnuty