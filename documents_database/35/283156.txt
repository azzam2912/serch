they are typically used in complex statistical models consisting of observed variables usually termed data as well as unknown parameters and latent variables with various sorts of relationships among the three types of random variables as might be described by a graphical model as typical in bayesian inference the parameters and latent variables are grouped together as unobserved variables variational bayesian methods are primarily used for two purposes in the former purpose that of approximating a posterior probability variational bayes is an alternative to monte carlo sampling methods particularly markov chain monte carlo methods such as gibbs sampling for taking a fully bayesian approach to statistical inference over complex distributions that are difficult to directly evaluate or sample from in particular whereas monte carlo techniques provide a numerical approximation to the exact posterior using a set of samples variational bayes provides a locally optimal exact analytical solution to an approximation of the posterior variational bayes can be seen as an extension of the em expectation maximization algorithm from maximum a posteriori estimation map estimation of the single most probable value of each parameter to fully bayesian estimation which computes an approximation to the entire posterior distribution of the parameters and