in a locally optimal manner samokish proposed applying a preconditioner formula 11 to the residual vector formula 12 to generate the preconditioned direction formula 13 and derived asymptotic as formula 9 approaches the eigenvector convergence rate bounds d yakonov suggested spectrally equivalent preconditioning and derived non asymptotic convergence rate bounds block locally optimal multi step steepest descent for eigenvalue problems was described in local minimization of the rayleigh quotient on the subspace spanned by the current approximation the current residual and the previous approximation as well as its block version appeared in the preconditioned version was analyzed in and the method performs an iterative maximization or minimization of the generalized rayleigh quotient which results in finding largest or smallest eigenpairs of formula 16 the direction of the steepest ascent which is the gradient of the generalized rayleigh quotient is positively proportional to the vector called the eigenvector residual if a preconditioner formula 11 is available it is applied to the residual and gives the vector called the preconditioned residual without preconditioning we set formula 20 and so formula 21 an iterative method or in short is known as preconditioned steepest ascent or descent where the scalar formula 26 is called