rbms have found applications in dimensionality reduction classification collaborative filtering feature learning topic modelling and even many body quantum mechanics they can be trained in either supervised or unsupervised ways depending on the task as their name implies rbms are a variant of boltzmann machines with the restriction that their neurons must form a bipartite graph a pair of nodes from each of the two groups of units commonly referred to as the visible and hidden units respectively may have a symmetric connection between them and there are no connections between nodes within a group by contrast unrestricted boltzmann machines may have connections between hidden units this restriction allows for more efficient training algorithms than are available for the general class of boltzmann machines in particular the gradient based contrastive divergence algorithm restricted boltzmann machines can also be used in deep learning networks in particular deep belief networks can be formed by stacking rbms and optionally fine tuning the resulting deep network with gradient descent and backpropagation the standard type of rbm has binary valued boolean bernoulli hidden and visible units and consists of a matrix of weights formula 1 size m n associated with the connection between hidden unit