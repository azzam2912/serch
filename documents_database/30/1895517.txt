transfer entropy from a process x to another process y is the amount of uncertainty reduced in future values of y by knowing the past values of x given past values of y more specifically if formula 1 and formula 2 for formula 3 denote two random processes and the amount of information is measured using shannon s entropy the transfer entropy can be written as where h x is shannon entropy of x the above definition of transfer entropy has been extended by other types of entropy measures such as r nyi entropy transfer entropy is conditional mutual information with the history of the influenced variable formula 5 in the condition transfer entropy reduces to granger causality for vector auto regressive processes hence it is advantageous when the model assumption of granger causality doesn t hold for example analysis of non linear signals however it usually requires more samples for accurate estimation the probabilities in the entropy formula can be estimated using different approaches binning nearest neighbors or in order to reduce complexity using a non uniform embedding while it was originally defined for bivariate analysis transfer entropy has been extended to multivariate forms either conditioning on other potential