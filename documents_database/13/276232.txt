it is a modification of newton s method for finding a minimum of a function unlike newton s method the gauss newton algorithm can only be used to minimize a sum of squared function values but it has the advantage that second derivatives which can be challenging to compute are not required non linear least squares problems arise for instance in non linear regression where parameters in a model are sought such that the model is in good agreement with available observations the method is named after the mathematicians carl friedrich gauss and isaac newton and first appeared in gauss 1809 work theoria motus corporum coelestium in sectionibus conicis solem ambientum given m functions r r r often called residuals of n variables with m n the gauss newton algorithm iteratively finds the value of the variables that minimizes the sum of squares starting with an initial guess formula 2 for the minimum the method proceeds by the iterations where if r and are column vectors the entries of the jacobian matrix are and the symbol formula 5 denotes the matrix transpose if m n the iteration simplifies to which is a direct generalization of newton s method in one