a simple bayesian model of written text contains only the dictionary of legal words and their relative probabilities a markovian model adds the relative transition probabilities that given one word predict what the next word will be it is based on the theory of markov chains by andrey markov hence the name in essence a bayesian filter works on single words alone while a markovian filter works on phrases or entire sentences there are two types of markov models the visible markov model and the hidden markov model or hmm the difference is that with a visible markov model the current word is considered to contain the entire state of the language model while a hidden markov model hides the state and presumes only that the current word is probabilistically related to the actual internal state of the language for example in a visible markov model the word the should predict with accuracy the following word while in a hidden markov model the entire prior text implies the actual state and predicts the following words but does not actually guarantee that state or prediction since the latter case is what s encountered in spam filtering hidden markov models are almost