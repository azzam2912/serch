the other component is the pure error sum of squares the pure error sum of squares is the sum of squared deviations of each value of the dependent variable from the average value over all observations sharing its independent variable value s these are errors that could never be avoided by any predictive equation that assigned a predicted value for the dependent variable as a function of the value s of the independent variable s the remainder of the residual sum of squares is attributed to lack of fit of the model since it would be mathematically possible to eliminate these errors entirely in order for the lack of fit sum of squares to differ from the sum of squares of residuals there must be more than one value of the response variable for at least one of the values of the set of predictor variables for example consider fitting a line by the method of least squares one takes as estimates of and the values that minimize the sum of squares of residuals i e the sum of squares of the differences between the observed y value and the fitted y value to have a lack of fit sum