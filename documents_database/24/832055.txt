there are various specific implementations to realize this if an application consists of a collection of processes working closely together and if some but not all of the processes are scheduled for execution the executing processes may attempt to communicate with those that are not executing which will cause them to block eventually the other processes will be scheduled for execution but by this time the situation may be reversed so that these processes also block waiting for interactions with others as a result the application makes progress at the rate of at most one interprocess interaction per time slice and will have low throughput and high latency coscheduling consists of two ideas some coscheduling techniques exhibit fragments of processes that do not run concurrently with the rest of the coscheduled set the occurrence of these fragments is usually minimized by these algorithms gang scheduling is a stricter variant of coscheduling that disallows fragments completely researchers have classified three types of coscheduling explicit coscheduling local scheduling and implicit or dynamic coscheduling explicit coscheduling requires all processing to actually take place at the same time and is typically implemented by global scheduling across all processors a specific algorithm is known as