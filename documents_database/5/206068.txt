it is in general a nonlinear partial differential equation in the value function which means its solution the value function itself once the solution is known it can be used to obtain the optimal control by taking the maximizer minimizer of the hamiltonian involved in the hjb equation the equation is a result of the theory of dynamic programming which was pioneered in the 1950s by richard bellman and coworkers the connection to the hamilton jacobi equation from classical physics was first drawn by rudolf k lm n in discrete time problems the equation is usually referred to as the bellman equation while classical variational problems for example the brachistochrone problem can be solved using the hamilton jacobi bellman equation the method can be applied to a broader spectrum of problems further it can be generalized to stochastic systems in which case the hjb equation is a second order partial differential equation a major drawback however is that the hjb equation admits classical solutions only for a sufficiently smooth value function which is not guaranteed in most situations instead the notion of a viscosity solution is required in which conventional derivatives are replaced by set valued subderivatives consider the following