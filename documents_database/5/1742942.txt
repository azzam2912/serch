as a result the same ideas can be represented using a smaller set of words in most applications semantic compression is a lossy compression that is increased prolixity does not compensate for the lexical compression and an original document cannot be reconstructed in a reverse process semantic compression is basically achieved in two steps using frequency dictionaries and semantic network step 1 requires assembling word frequencies and information on semantic relationships specifically hyponymy moving upwards in word hierarchy a cumulative concept frequency is calculating by adding a sum of hyponyms frequencies to frequency of their hypernym formula 1 where formula 2 is a hypernym of formula 3 then a desired number of words with top cumulated frequencies are chosen to build a targed lexicon in the second step compression mapping rules are defined for the remaining words in order to handle every occurrence of a less frequent hyponym as its hypernym in output text the below fragment of text has been processed by the semantic compression words in bold have been replaced by their hypernyms they are both nest building social insects but paper wasps and honey bees organize their colonies in very different ways in a new study researchers