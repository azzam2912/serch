a full model is fitted to data using standard approaches hypotheses are then tested by defining one or more reduced models with alternative and usually more restrictive priors which usually in the limit switch off certain parameters the evidence and parameters of the reduced models can then be computed from the evidence and estimated posterior parameters of the full model using bayesian model reduction if the priors and posteriors are normally distributed then there is an analytic solution which can be computed rapidly this has multiple scientific and engineering applications these include scoring the evidence for large numbers of models very quickly and facilitating the estimation of hierarchical models parametric empirical bayes consider some model with parameters formula 1 and a prior probability density on those parameters formula 2 the posterior belief about formula 1 after seeing the data formula 4 is given by bayes rule the second line of equation 1 is the model evidence which is the probability of observing the data given the model in practice the posterior cannot usually be computed analytically due to the difficulty in computing the integral over the parameters therefore the posteriors are estimated using approaches such as mcmc sampling or variational