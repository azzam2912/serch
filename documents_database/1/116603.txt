it is named after the russian mathematician andrey markov a stochastic process has the markov property if the conditional probability distribution of future states of the process conditional on both past and present states depends only upon the present state not on the sequence of events that preceded it a process with this property is called a markov process the term strong markov property is similar to the markov property except that the meaning of present is defined in terms of a random variable known as a stopping time the term markov assumption is used to describe a model where the markov property is assumed to hold such as a hidden markov model a markov random field extends this property to two or more dimensions or to random variables defined for an interconnected network of items an example of a model for such a field is the ising model a discrete time stochastic process satisfying the markov property is known as a markov chain a stochastic process has the markov property if the conditional probability distribution of future states of the process conditional on both past and present values depends only upon the present state that is given the present